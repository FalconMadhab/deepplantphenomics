## Multithreading Options

```
set_number_of_threads()
```

Set number of threads for input queue runners and preprocessing tasks. Using more threads won't accelerate training or inference, but if you're using a GPU then you should make sure that you're using enough threads that no single thread is running at 100% load if possible.

Note that all pre-trained networks operate with only one thread to avoid random orderings due to threading.

## Learning Hyperparameters

```
set_batch_size()
```

Sets the number of examples in each mini-batch. Recall that smaller batches mean more gradient updates per epoch.

```
set_maximum_training_epochs()
```

Sets the number of epochs to train to before stopping. An epoch is one full cycle through the entire training set.

```
set_learning_rate()
```

Set the initial learning rate. If you're not sure what learning rate is appropriate, err on the side of a smaller learning rate.

```
set_optimizer()
```

Set the optimization algorithm to use. Default is `'Adam'`. Other options are `'SGD'` (Stochastic Gradient Descent), `'Adadelta'`, and `'Adagrad'`.

```
set_learning_rate_decay(decay_factor, epochs_per_decay)
```

Manually anneal the learning rate every `epochs_per_decay` epochs. This isn't necessary for gradient-adaptive optimizers like `'Adam'`.

```
set_regularization_coefficient()
```

Set the coefficient for L2 weight decay (regularization).

```
set_weight_initializer()
```

Set the weight initialization scheme for convolutional and fully connected layers. Default is `'normal'`, other option is `'xavier'`. Note that you may experience gradient problems with relu activations and xavier initialization.

```
set_problem_type()
```

Set the type of problem for the model. Possible problem types include:
- `classification` (default)
- `regression`
- `semantic_segmentation` (pixel-wise regression with a fully convolutional network, useful for segmentation applications; see [semantic segmentation](/Semantic-Segmentation/))
- `object_detection` (a one-class object detector based on [Yolov2](https://arxiv.org/pdf/1612.08242.pdf))

```
set_train_test_split()
```

Set the ratio of training samples to testing samples (assuming no validation samples).

This method has been deprecated. `set_test_split()` and `set_validation_split()` should be used instead.

```
set_test_split()
```

Set the ratio of the total number of samples to use as a testing set after training.

```
set_validation_split()
```

Set the ratio of the total number of samples to use as a validation set during training.

## Input Options

```
set_image_dimensions(image_height, image_width, image_depth)
```

Specify the image dimensions for images in the dataset (depth is the number of channels). This can be the dimensions you want to resize to if you're using `set_resize_images()` or `set_crop_or_pad_images()`.

```
set_original_image_dimensions(image_height, image_width)
```

Specify the original size of the image, before resizing. This is only needed in special cases, for instance, if you are resizing input images but using image coordinate labels which reference the original size.

```
add_preprocessor()
```

Add pre-processors. For more information see the documentation for pre-processors.

```
set_crop_or_pad_images(True)
```

Resize images by cropping or padding, as opposed to plain resizing.

```
set_resize_images(True)
```

Up-sample or down-sample images to specified size.

```
set_processed_images_dir()
```

Set the location to save processed images when pre-processing is used.

## Data Augmentation Options

```
set_augmentation_flip_horizontal(True)
```

Randomly flip training images horizontally.

```
set_augmentation_flip_vertical(True)
```

Randomly flip training images vertically.

```
set_augmentation_crop(True, crop_ratio)
```

Randomly crop images during training, and crop images to center during testing. The size of the crop is specified by `crop_ratio`, and defaults to `0.75`, or 75% of the original image.

```
set_augmentation_brightness_and_contrast(True)
```

Randomly adjust contrast and/or brightness on training images.

```
set_augmentation_rotation(True, crop_borders=False)
```

Randomly rotate training images by any angle within 0-360 degrees (for classification and regression tasks). Parts of the image may get rotated outside of the image after rotation. By default, this will also leave black borders around the image. Setting `crop_borders` to `True` will perform a centre crop to remove the black borders generated by rotation.

<b>A warning on using centre cropping with rotation augmentation:</b> In order to maintain similar feature scales between images, the cropping uses the tightest possible crop required for any given image to remove black borders (i.e. the crop required for 45 degree rotation). This will crop out at least 50% of the image (more for higher aspect ratios). If using this, ensure that the main content of the images is in the centre.


```
load_training_augmentation_dataset_from_directory_with_csv_labels(dirname, labels_file, column_number, id_column_number)
```

Load a second set of images with corresponding labels in a csv file to augment the training set with. This is a good option if your chosen augmentation is not listed above - you can create the augmented examples yourself and load them with this function. `column_number` should have the label and `id_column_number` should have the filename.

```
set_patch_size(height=128, width=128)
```

Train on randomly extracted patches, of size `height`x`width`, of the original images. Testing is then performed by splitting the image into patches of `height`x`width`, passing the patches individually through the network, and then stitching the results back together to form the full image. 

## YOLO Object Detection Parameters

```
set_yolo_parameters(grid_size=[7,7],
                    class_list=['plant'], 
                    anchors=[[159, 157], [103, 133], [91, 89], [64, 65], [142, 101]])
```

Sets several parameters needed for the Yolo-based object detector.

- Yolo splits images into a grid and makes bounding box predictions in each grid square.`grid_size` defines the number of grid squares along the image width and height. Defaults to [7,7].
- `class_list` is a list of names for possible object classes in images. This defaults to a single 'plant' class. (DPP currently only supports one class at a time)
- `anchors` defines the widths and heights of anchors/prior boxes which the bounding box predictions use as a basis for detecting objects of various sizes and aspect ratios. The five anchors listed above are the default values and should be fine for most detectors.